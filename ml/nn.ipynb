{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import compute_class_weight\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                 Time         V1         V2         V3        V4         V5  \\\n",
      "0       82450.000000   1.314539   0.590643  -0.666593  0.716564   0.301978   \n",
      "1       50554.000000  -0.798672   1.185093   0.904547  0.694584   0.219041   \n",
      "2       55125.000000  -0.391128  -0.245540   1.122074 -1.308725  -0.639891   \n",
      "3      116572.000000  -0.060302   1.065093  -0.987421 -0.029567   0.176376   \n",
      "4       90434.000000   1.848433   0.373364   0.269272  3.866438   0.088062   \n",
      "...              ...        ...        ...        ...       ...        ...   \n",
      "13803   28660.144835 -28.553925  15.889210 -29.492664  6.448861 -20.805347   \n",
      "13804  150305.516421  -2.679064  -0.939409  -3.899026  2.935596   0.009975   \n",
      "13805   91713.789482   0.931282   2.237816  -4.965300  2.593112   1.230142   \n",
      "13806   94362.000000 -26.457745  16.497472 -30.177317  8.904157 -17.892600   \n",
      "13807  116425.974840  -0.057156   1.913101  -5.120289  2.445768  -1.101931   \n",
      "\n",
      "             V6         V7         V8        V9  ...       V21       V22  \\\n",
      "0     -1.125467   0.388881  -0.288390 -0.132137  ... -0.170307 -0.429655   \n",
      "1     -0.319295   0.495236   0.139269 -0.760214  ...  0.202287  0.578699   \n",
      "2      0.008678  -0.701304  -0.027315 -2.628854  ... -0.133485  0.117403   \n",
      "3     -1.348539   0.775644   0.134843 -0.149734  ...  0.355576  0.907570   \n",
      "4      0.970447  -0.721945   0.235983  0.683491  ...  0.103563  0.620954   \n",
      "...         ...        ...        ...       ...  ...       ...       ...   \n",
      "13803 -4.867228 -19.513801  18.767278 -3.641856  ...  1.805909 -2.121851   \n",
      "13804 -0.797891   0.431915   0.272109 -0.800646  ...  0.043036  0.547563   \n",
      "13805 -1.907136  -0.233550   0.236582  0.531390  ... -0.039930 -0.266658   \n",
      "13806 -1.227904 -31.197329 -11.438920 -9.462573  ... -8.755698  3.460893   \n",
      "13807 -2.091941  -2.555234  -0.471140 -0.911369  ...  1.071155 -0.948875   \n",
      "\n",
      "            V23       V24       V25       V26       V27       V28      Amount  \\\n",
      "0     -0.141341 -0.200195  0.639491  0.399476 -0.034321  0.031692    0.760000   \n",
      "1     -0.092245  0.013723 -0.246466 -0.380057 -0.396030 -0.112901    4.180000   \n",
      "2     -0.191748 -0.488642 -0.309774  0.008100  0.163716  0.239582   15.000000   \n",
      "3     -0.018454 -0.126269 -0.339923 -0.150285 -0.023634  0.042330   57.000000   \n",
      "4      0.197077  0.692392 -0.206530 -0.021328 -0.019823 -0.042682    0.000000   \n",
      "...         ...       ...       ...       ...       ...       ...         ...   \n",
      "13803 -1.319589  0.170045  2.053971 -0.210476  1.300744  0.379892   99.990000   \n",
      "13804  0.191170 -0.105009  0.453638  0.092923 -0.009364  0.062747  126.439804   \n",
      "13805  0.037623 -0.114400  0.010539 -0.501890  0.093685  0.124299    6.680319   \n",
      "13806  0.896538  0.254836 -0.738097 -0.966564 -7.263482 -1.324884    1.000000   \n",
      "13807  0.283795 -0.219956  0.032231 -0.023198  0.576043  0.483584   70.954759   \n",
      "\n",
      "       Class  \n",
      "0        0.0  \n",
      "1        0.0  \n",
      "2        0.0  \n",
      "3        0.0  \n",
      "4        0.0  \n",
      "...      ...  \n",
      "13803    1.0  \n",
      "13804    1.0  \n",
      "13805    1.0  \n",
      "13806    1.0  \n",
      "13807    1.0  \n",
      "\n",
      "[13808 rows x 31 columns]>\n",
      "(13808, 30)\n",
      "(9665, 30)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/creditcard_newds.csv')\n",
    "ds = df.to_numpy()\n",
    "y = ds[:, -1] # for last column\n",
    "x = ds[:, :-1] # for all but last column\n",
    "\n",
    "\n",
    "#under = RandomUnderSampler()\n",
    "#steps = [('u', under)]\n",
    "#pipeline = Pipeline(steps=steps)\n",
    "#X_sampled, y_sampled = pipeline.fit_resample(x, y)\n",
    "#print('class 0: ',len(y_sampled[y_sampled == 0]))\n",
    "#print('class 1:', len(y_sampled[y_sampled == 1]))\n",
    "#x, y = X_sampled, y_sampled\n",
    "\n",
    "print(df.head)\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# ein beispielhaftes NN model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_shape=(30,), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, input_shape=(30,), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(30, input_shape=(30,), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, input_shape=(30,), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 0.8507922535211268, 1.0: 1.21267252195734}\n",
      "Epoch 1/100\n",
      "152/152 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5302\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 0s 865us/step - loss: 0.6932 - accuracy: 0.5193\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 0s 908us/step - loss: 0.6931 - accuracy: 0.5876\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 0s 968us/step - loss: 0.6932 - accuracy: 0.4292\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 0s 908us/step - loss: 0.6952 - accuracy: 0.4124\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 0s 866us/step - loss: 0.6935 - accuracy: 0.4123\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.7875 - accuracy: 0.4123\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 0s 864us/step - loss: 0.6960 - accuracy: 0.4123\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4124\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 0s 865us/step - loss: 0.6931 - accuracy: 0.4124\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6931 - accuracy: 0.5063\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6934 - accuracy: 0.5625\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 0s 865us/step - loss: 0.6932 - accuracy: 0.5877\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4659\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5559\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 0s 805us/step - loss: 0.6934 - accuracy: 0.4122\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 0s 969us/step - loss: 0.6932 - accuracy: 0.4123\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 0s 908us/step - loss: 0.6932 - accuracy: 0.4122\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6932 - accuracy: 0.4122\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6936 - accuracy: 0.5180\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6932 - accuracy: 0.5226\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 0s 770us/step - loss: 0.6934 - accuracy: 0.5268\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 0s 898us/step - loss: 0.6932 - accuracy: 0.4790\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 0s 969us/step - loss: 0.6931 - accuracy: 0.4124\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 0s 865us/step - loss: 0.6932 - accuracy: 0.5693\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 0s 805us/step - loss: 0.6962 - accuracy: 0.4690\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6933 - accuracy: 0.5876\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6931 - accuracy: 0.5877\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6932 - accuracy: 0.5877\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6932 - accuracy: 0.5876\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6932 - accuracy: 0.5877\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 0s 806us/step - loss: 0.6932 - accuracy: 0.5877\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6931 - accuracy: 0.5737\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6932 - accuracy: 0.4123\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6932 - accuracy: 0.4123\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6931 - accuracy: 0.5065\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6932 - accuracy: 0.4122\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6932 - accuracy: 0.4124\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 0s 771us/step - loss: 0.6931 - accuracy: 0.5874\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6931 - accuracy: 0.5878\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6960 - accuracy: 0.5876\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6932 - accuracy: 0.4378\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6932 - accuracy: 0.5877\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6932 - accuracy: 0.4148\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4251\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4337\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6932 - accuracy: 0.5877\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 0s 865us/step - loss: 0.6931 - accuracy: 0.5877\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5877\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 0s 865us/step - loss: 0.6932 - accuracy: 0.5877\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6932 - accuracy: 0.5111\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6932 - accuracy: 0.5877\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 0s 702us/step - loss: 0.6932 - accuracy: 0.4136\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6932 - accuracy: 0.4123\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 0s 761us/step - loss: 0.6932 - accuracy: 0.4854\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6932 - accuracy: 0.4123\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 0s 865us/step - loss: 0.6932 - accuracy: 0.4690\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 0s 805us/step - loss: 0.6931 - accuracy: 0.4998\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6931 - accuracy: 0.5350\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6932 - accuracy: 0.5291\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6932 - accuracy: 0.5877\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6932 - accuracy: 0.5877\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6978 - accuracy: 0.5877\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6955 - accuracy: 0.5877\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 0s 805us/step - loss: 0.6932 - accuracy: 0.5877\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6932 - accuracy: 0.5877\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6931 - accuracy: 0.4570\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6932 - accuracy: 0.4123\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 0s 771us/step - loss: 0.6932 - accuracy: 0.5813\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 0s 753us/step - loss: 0.6934 - accuracy: 0.4153\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6932 - accuracy: 0.4123\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 0s 771us/step - loss: 0.6931 - accuracy: 0.4495\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6931 - accuracy: 0.5832\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6967 - accuracy: 0.5876\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6931 - accuracy: 0.4356\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6932 - accuracy: 0.4560\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6931 - accuracy: 0.4783\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6954 - accuracy: 0.5639\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6949 - accuracy: 0.4193\n",
      "Epoch 80/100\n",
      "152/152 [==============================] - 0s 805us/step - loss: 0.6934 - accuracy: 0.4123\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6932 - accuracy: 0.4122\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6932 - accuracy: 0.4123\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6932 - accuracy: 0.4123\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6996 - accuracy: 0.4122\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6932 - accuracy: 0.4123\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6931 - accuracy: 0.4122\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.7024 - accuracy: 0.4124\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 0s 805us/step - loss: 0.6933 - accuracy: 0.4123\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6932 - accuracy: 0.4123\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 0s 761us/step - loss: 0.6932 - accuracy: 0.4123\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6931 - accuracy: 0.4123\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6932 - accuracy: 0.4122\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6941 - accuracy: 0.4122\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 0s 759us/step - loss: 0.6931 - accuracy: 0.4123\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 0s 762us/step - loss: 0.6932 - accuracy: 0.4485\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6932 - accuracy: 0.4123\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6932 - accuracy: 0.4882\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6931 - accuracy: 0.4300\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 0s 763us/step - loss: 0.6931 - accuracy: 0.4122\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 0s 660us/step - loss: 0.6971 - accuracy: 0.4175\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1fcaabc6040>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(y_train),\n",
    "                                        y = y_train\n",
    "                                    )\n",
    "class_weights = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "print(class_weights)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, shuffle=True, class_weight=class_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation of NN model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions[predictions <= 0.5] = 0.\n",
    "predictions[predictions > 0.5] = 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4105720492396814\n",
      "Precision:  1.0\n",
      "Recall:  0.4105720492396814\n",
      "false positive rate 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(predictions, y_test))\n",
    "print('Precision: ', precision_score(predictions, y_test))\n",
    "print('Recall: ', recall_score(predictions, y_test))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "false_positive_rate = fp / (fp + tn)\n",
    "\n",
    "print('false positive rate', false_positive_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Frauds:  1701\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "print('Anzahl der Frauds: ', len(y_test[y_test==1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}